{
    "overall": {
        "accuracy": 0.458780423972782,
        "macro avg": {
            "precision": 0.547727227403932,
            "recall": 0.4826417128368461,
            "f1-score": 0.4590474609249435,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.6316521630401151,
            "recall": 0.458780423972782,
            "f1-score": 0.4804764644930466,
            "support": 3821
        }
    },
    "Angry": {
        "precision": 0.5247524752475248,
        "recall": 0.12211981566820276,
        "f1-score": 0.19813084112149534,
        "accuracy": 0.12211981566820276,
        "support": 434,
        "True Positives": 53,
        "False Positives": 48,
        "False Negatives": 381,
        "True Negatives": 3339
    },
    "Disgust": {
        "precision": 0.27013752455795675,
        "recall": 0.6740196078431373,
        "f1-score": 0.3856942496493688,
        "accuracy": 0.6740196078431373,
        "support": 408,
        "True Positives": 275,
        "False Positives": 743,
        "False Negatives": 133,
        "True Negatives": 2670
    },
    "Fear": {
        "precision": 0.5765765765765766,
        "recall": 0.4169381107491857,
        "f1-score": 0.4839319470699433,
        "accuracy": 0.4169381107491857,
        "support": 307,
        "True Positives": 128,
        "False Positives": 94,
        "False Negatives": 179,
        "True Negatives": 3420
    },
    "Happiness": {
        "precision": 0.9578313253012049,
        "recall": 0.40253164556962023,
        "f1-score": 0.5668449197860962,
        "accuracy": 0.40253164556962023,
        "support": 1185,
        "True Positives": 477,
        "False Positives": 21,
        "False Negatives": 708,
        "True Negatives": 2615
    },
    "Neutral": {
        "precision": 0.49911504424778763,
        "recall": 0.4147058823529412,
        "f1-score": 0.4530120481927711,
        "accuracy": 0.4147058823529412,
        "support": 680,
        "True Positives": 282,
        "False Positives": 283,
        "False Negatives": 398,
        "True Negatives": 2858
    },
    "Sadness": {
        "precision": 0.6260330578512396,
        "recall": 0.6338912133891214,
        "f1-score": 0.6299376299376299,
        "accuracy": 0.6338912133891214,
        "support": 478,
        "True Positives": 303,
        "False Positives": 181,
        "False Negatives": 175,
        "True Negatives": 3162
    },
    "Surprise": {
        "precision": 0.37964458804523427,
        "recall": 0.7142857142857143,
        "f1-score": 0.4957805907172996,
        "accuracy": 0.7142857142857143,
        "support": 329,
        "True Positives": 235,
        "False Positives": 384,
        "False Negatives": 94,
        "True Negatives": 3108
    }
}