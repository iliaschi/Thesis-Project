{
    "overall": {
        "accuracy": 0.4593038471604292,
        "macro avg": {
            "precision": 0.4912355734099858,
            "recall": 0.42171151288484177,
            "f1-score": 0.4110275660345545,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.6435251095063108,
            "recall": 0.4593038471604292,
            "f1-score": 0.49101423037320074,
            "support": 3821
        }
    },
    "Angry": {
        "precision": 0.5481481481481482,
        "recall": 0.17050691244239632,
        "f1-score": 0.2601054481546573,
        "accuracy": 0.17050691244239632,
        "support": 434,
        "True Positives": 74,
        "False Positives": 61,
        "False Negatives": 360,
        "True Negatives": 3326
    },
    "Contempt": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "accuracy": 0.0,
        "support": 0,
        "True Positives": 0,
        "False Positives": 370,
        "False Negatives": 0,
        "True Negatives": 3451
    },
    "Disgust": {
        "precision": 0.2622641509433962,
        "recall": 0.6813725490196079,
        "f1-score": 0.3787465940054496,
        "accuracy": 0.6813725490196079,
        "support": 408,
        "True Positives": 278,
        "False Positives": 782,
        "False Negatives": 130,
        "True Negatives": 2631
    },
    "Fear": {
        "precision": 0.5866666666666667,
        "recall": 0.42996742671009774,
        "f1-score": 0.4962406015037594,
        "accuracy": 0.42996742671009774,
        "support": 307,
        "True Positives": 132,
        "False Positives": 93,
        "False Negatives": 175,
        "True Negatives": 3421
    },
    "Happiness": {
        "precision": 0.9499036608863198,
        "recall": 0.4160337552742616,
        "f1-score": 0.5786384976525821,
        "accuracy": 0.4160337552742616,
        "support": 1185,
        "True Positives": 493,
        "False Positives": 26,
        "False Negatives": 692,
        "True Negatives": 2610
    },
    "Neutral": {
        "precision": 0.5415821501014199,
        "recall": 0.3926470588235294,
        "f1-score": 0.4552429667519181,
        "accuracy": 0.3926470588235294,
        "support": 680,
        "True Positives": 267,
        "False Positives": 226,
        "False Negatives": 413,
        "True Negatives": 2915
    },
    "Sadness": {
        "precision": 0.6536697247706422,
        "recall": 0.5962343096234309,
        "f1-score": 0.6236323851203501,
        "accuracy": 0.5962343096234309,
        "support": 478,
        "True Positives": 285,
        "False Positives": 151,
        "False Negatives": 193,
        "True Negatives": 3192
    },
    "Surprise": {
        "precision": 0.3876500857632933,
        "recall": 0.6869300911854104,
        "f1-score": 0.4956140350877192,
        "accuracy": 0.6869300911854104,
        "support": 329,
        "True Positives": 226,
        "False Positives": 357,
        "False Negatives": 103,
        "True Negatives": 3135
    }
}