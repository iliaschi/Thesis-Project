{
    "overall": {
        "accuracy": 0.09473959696414551,
        "macro avg": {
            "precision": 0.10157427928773212,
            "recall": 0.10984427416118199,
            "f1-score": 0.08433185438350228,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.12838717161741575,
            "recall": 0.09473959696414551,
            "f1-score": 0.07598103362435556,
            "support": 3821
        }
    },
    "per_class": {},
    "Angry": {
        "precision": 0.18449197860962566,
        "recall": 0.31797235023041476,
        "f1-score": 0.23350253807106597,
        "accuracy": 0.31797235023041476,
        "support": 434,
        "tp": 138,
        "fp": 610,
        "fn": 296,
        "tn": 2777
    },
    "Contempt": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "accuracy": 0.0,
        "support": 0,
        "tp": 0,
        "fp": 637,
        "fn": 0,
        "tn": 3184
    },
    "Disgust": {
        "precision": 0.12090163934426229,
        "recall": 0.28921568627450983,
        "f1-score": 0.17052023121387283,
        "accuracy": 0.28921568627450983,
        "support": 408,
        "tp": 118,
        "fp": 858,
        "fn": 290,
        "tn": 2555
    },
    "Fear": {
        "precision": 0.13176470588235295,
        "recall": 0.18241042345276873,
        "f1-score": 0.15300546448087432,
        "accuracy": 0.18241042345276873,
        "support": 307,
        "tp": 56,
        "fp": 369,
        "fn": 251,
        "tn": 3145
    },
    "Happiness": {
        "precision": 0.16901408450704225,
        "recall": 0.010126582278481013,
        "f1-score": 0.01910828025477707,
        "accuracy": 0.010126582278481013,
        "support": 1185,
        "tp": 12,
        "fp": 59,
        "fn": 1173,
        "tn": 2577
    },
    "Neutral": {
        "precision": 0.1415929203539823,
        "recall": 0.023529411764705882,
        "f1-score": 0.0403530895334174,
        "accuracy": 0.023529411764705882,
        "support": 680,
        "tp": 16,
        "fp": 97,
        "fn": 664,
        "tn": 3044
    },
    "Sadness": {
        "precision": 0.018957345971563982,
        "recall": 0.02510460251046025,
        "f1-score": 0.021602160216021606,
        "accuracy": 0.02510460251046025,
        "support": 478,
        "tp": 12,
        "fp": 621,
        "fn": 466,
        "tn": 2722
    },
    "Surprise": {
        "precision": 0.045871559633027525,
        "recall": 0.030395136778115502,
        "f1-score": 0.03656307129798903,
        "accuracy": 0.030395136778115502,
        "support": 329,
        "tp": 10,
        "fp": 208,
        "fn": 319,
        "tn": 3284
    }
}