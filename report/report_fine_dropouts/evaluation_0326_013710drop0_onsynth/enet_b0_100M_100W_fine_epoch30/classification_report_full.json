{
    "overall": {
        "accuracy": 0.8367609254498715,
        "macro avg": {
            "precision": 0.835124850550845,
            "recall": 0.8360816322337554,
            "f1-score": 0.8344209758539874,
            "support": 778
        },
        "weighted avg": {
            "precision": 0.8377122002621354,
            "recall": 0.8367609254498715,
            "f1-score": 0.8361079425878442,
            "support": 778
        }
    },
    "Angry": {
        "precision": 0.7037037037037037,
        "recall": 0.8085106382978723,
        "f1-score": 0.7524752475247524,
        "accuracy": 0.8085106382978723,
        "support": 94,
        "True Positives": 76,
        "False Positives": 32,
        "False Negatives": 18,
        "True Negatives": 652
    },
    "Contempt": {
        "precision": 0.7901234567901234,
        "recall": 0.735632183908046,
        "f1-score": 0.761904761904762,
        "accuracy": 0.735632183908046,
        "support": 87,
        "True Positives": 64,
        "False Positives": 17,
        "False Negatives": 23,
        "True Negatives": 674
    },
    "Disgust": {
        "precision": 0.7738095238095238,
        "recall": 0.6914893617021277,
        "f1-score": 0.7303370786516854,
        "accuracy": 0.6914893617021277,
        "support": 94,
        "True Positives": 65,
        "False Positives": 19,
        "False Negatives": 29,
        "True Negatives": 665
    },
    "Fear": {
        "precision": 0.8482142857142857,
        "recall": 0.8050847457627118,
        "f1-score": 0.8260869565217391,
        "accuracy": 0.8050847457627118,
        "support": 118,
        "True Positives": 95,
        "False Positives": 17,
        "False Negatives": 23,
        "True Negatives": 643
    },
    "Happiness": {
        "precision": 0.9702970297029703,
        "recall": 0.98989898989899,
        "f1-score": 0.98,
        "accuracy": 0.98989898989899,
        "support": 99,
        "True Positives": 98,
        "False Positives": 3,
        "False Negatives": 1,
        "True Negatives": 676
    },
    "Neutral": {
        "precision": 0.8478260869565217,
        "recall": 0.9285714285714286,
        "f1-score": 0.8863636363636365,
        "accuracy": 0.9285714285714286,
        "support": 84,
        "True Positives": 78,
        "False Positives": 14,
        "False Negatives": 6,
        "True Negatives": 680
    },
    "Sadness": {
        "precision": 0.8849557522123894,
        "recall": 0.8771929824561403,
        "f1-score": 0.8810572687224669,
        "accuracy": 0.8771929824561403,
        "support": 114,
        "True Positives": 100,
        "False Positives": 13,
        "False Negatives": 14,
        "True Negatives": 651
    },
    "Surprise": {
        "precision": 0.8620689655172413,
        "recall": 0.8522727272727273,
        "f1-score": 0.8571428571428572,
        "accuracy": 0.8522727272727273,
        "support": 88,
        "True Positives": 75,
        "False Positives": 12,
        "False Negatives": 13,
        "True Negatives": 678
    }
}