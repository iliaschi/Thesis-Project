{
    "overall": {
        "accuracy": 0.6199947657681235,
        "macro avg": {
            "precision": 0.5692476611167994,
            "recall": 0.5173749377756245,
            "f1-score": 0.5293566853555609,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.7087988209353255,
            "recall": 0.6199947657681235,
            "f1-score": 0.6498991289611911,
            "support": 3821
        }
    },
    "per_class": {},
    "Angry": {
        "precision": 0.7142857142857143,
        "recall": 0.38018433179723504,
        "f1-score": 0.4962406015037595,
        "accuracy": 0.38018433179723504,
        "support": 434,
        "tp": 165,
        "fp": 66,
        "fn": 269,
        "tn": 3321
    },
    "Contempt": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "accuracy": 0.0,
        "support": 0,
        "tp": 0,
        "fp": 292,
        "fn": 0,
        "tn": 3529
    },
    "Disgust": {
        "precision": 0.3788546255506608,
        "recall": 0.6323529411764706,
        "f1-score": 0.4738292011019284,
        "accuracy": 0.6323529411764706,
        "support": 408,
        "tp": 258,
        "fp": 423,
        "fn": 150,
        "tn": 2990
    },
    "Fear": {
        "precision": 0.594488188976378,
        "recall": 0.49185667752442996,
        "f1-score": 0.5383244206773619,
        "accuracy": 0.49185667752442996,
        "support": 307,
        "tp": 151,
        "fp": 103,
        "fn": 156,
        "tn": 3411
    },
    "Happiness": {
        "precision": 0.8853955375253549,
        "recall": 0.7367088607594937,
        "f1-score": 0.8042376784891755,
        "accuracy": 0.7367088607594937,
        "support": 1185,
        "tp": 873,
        "fp": 113,
        "fn": 312,
        "tn": 2523
    },
    "Neutral": {
        "precision": 0.73558648111332,
        "recall": 0.5441176470588235,
        "f1-score": 0.62552831783601,
        "accuracy": 0.5441176470588235,
        "support": 680,
        "tp": 370,
        "fp": 133,
        "fn": 310,
        "tn": 3008
    },
    "Sadness": {
        "precision": 0.685370741482966,
        "recall": 0.7154811715481172,
        "f1-score": 0.7001023541453429,
        "accuracy": 0.7154811715481172,
        "support": 478,
        "tp": 342,
        "fp": 157,
        "fn": 136,
        "tn": 3186
    },
    "Surprise": {
        "precision": 0.56,
        "recall": 0.6382978723404256,
        "f1-score": 0.5965909090909092,
        "accuracy": 0.6382978723404256,
        "support": 329,
        "tp": 210,
        "fp": 165,
        "fn": 119,
        "tn": 3327
    }
}