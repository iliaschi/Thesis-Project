{
    "overall": {
        "accuracy": 0.46061240512954726,
        "macro avg": {
            "precision": 0.4765849111752538,
            "recall": 0.42095522223200493,
            "f1-score": 0.40301758477013094,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.6273665754651506,
            "recall": 0.46061240512954726,
            "f1-score": 0.48319549054703737,
            "support": 3821
        }
    },
    "per_class": {},
    "Angry": {
        "precision": 0.5283018867924528,
        "recall": 0.12903225806451613,
        "f1-score": 0.2074074074074074,
        "accuracy": 0.12903225806451613,
        "support": 434,
        "tp": 56,
        "fp": 50,
        "fn": 378,
        "tn": 3337
    },
    "Contempt": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "accuracy": 0.0,
        "support": 0,
        "tp": 0,
        "fp": 314,
        "fn": 0,
        "tn": 3507
    },
    "Disgust": {
        "precision": 0.27037773359840955,
        "recall": 0.6666666666666666,
        "f1-score": 0.38472418670438474,
        "accuracy": 0.6666666666666666,
        "support": 408,
        "tp": 272,
        "fp": 734,
        "fn": 136,
        "tn": 2679
    },
    "Fear": {
        "precision": 0.5688888888888889,
        "recall": 0.4169381107491857,
        "f1-score": 0.48120300751879697,
        "accuracy": 0.4169381107491857,
        "support": 307,
        "tp": 128,
        "fp": 97,
        "fn": 179,
        "tn": 3417
    },
    "Happiness": {
        "precision": 0.9571150097465887,
        "recall": 0.41434599156118146,
        "f1-score": 0.5783274440518257,
        "accuracy": 0.41434599156118146,
        "support": 1185,
        "tp": 491,
        "fp": 22,
        "fn": 694,
        "tn": 2614
    },
    "Neutral": {
        "precision": 0.47877758913412566,
        "recall": 0.4147058823529412,
        "f1-score": 0.4444444444444444,
        "accuracy": 0.4147058823529412,
        "support": 680,
        "tp": 282,
        "fp": 307,
        "fn": 398,
        "tn": 2834
    },
    "Sadness": {
        "precision": 0.6116700201207244,
        "recall": 0.6359832635983264,
        "f1-score": 0.6235897435897437,
        "accuracy": 0.6359832635983264,
        "support": 478,
        "tp": 304,
        "fp": 193,
        "fn": 174,
        "tn": 3150
    },
    "Surprise": {
        "precision": 0.3975481611208406,
        "recall": 0.6899696048632219,
        "f1-score": 0.5044444444444445,
        "accuracy": 0.6899696048632219,
        "support": 329,
        "tp": 227,
        "fp": 344,
        "fn": 102,
        "tn": 3148
    }
}