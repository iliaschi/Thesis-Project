{
    "overall": {
        "accuracy": 0.46165925150484166,
        "macro avg": {
            "precision": 0.4853310951438859,
            "recall": 0.42395704713059557,
            "f1-score": 0.4067855393315914,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.6377863986996496,
            "recall": 0.46165925150484166,
            "f1-score": 0.48697881461755654,
            "support": 3821
        }
    },
    "per_class": {},
    "Angry": {
        "precision": 0.5229357798165137,
        "recall": 0.1313364055299539,
        "f1-score": 0.20994475138121543,
        "accuracy": 0.1313364055299539,
        "support": 434,
        "tp": 57,
        "fp": 52,
        "fn": 377,
        "tn": 3335
    },
    "Contempt": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "accuracy": 0.0,
        "support": 0,
        "tp": 0,
        "fp": 316,
        "fn": 0,
        "tn": 3505
    },
    "Disgust": {
        "precision": 0.26481835564053535,
        "recall": 0.678921568627451,
        "f1-score": 0.3810178817056396,
        "accuracy": 0.678921568627451,
        "support": 408,
        "tp": 277,
        "fp": 769,
        "fn": 131,
        "tn": 2644
    },
    "Fear": {
        "precision": 0.5851528384279476,
        "recall": 0.4364820846905538,
        "f1-score": 0.5000000000000001,
        "accuracy": 0.4364820846905538,
        "support": 307,
        "tp": 134,
        "fp": 95,
        "fn": 173,
        "tn": 3419
    },
    "Happiness": {
        "precision": 0.9568627450980393,
        "recall": 0.4118143459915612,
        "f1-score": 0.575811209439528,
        "accuracy": 0.4118143459915612,
        "support": 1185,
        "tp": 488,
        "fp": 22,
        "fn": 697,
        "tn": 2614
    },
    "Neutral": {
        "precision": 0.5097345132743363,
        "recall": 0.4235294117647059,
        "f1-score": 0.4626506024096385,
        "accuracy": 0.4235294117647059,
        "support": 680,
        "tp": 288,
        "fp": 277,
        "fn": 392,
        "tn": 2864
    },
    "Sadness": {
        "precision": 0.6620370370370371,
        "recall": 0.5983263598326359,
        "f1-score": 0.6285714285714286,
        "accuracy": 0.5983263598326359,
        "support": 478,
        "tp": 286,
        "fp": 146,
        "fn": 192,
        "tn": 3197
    },
    "Surprise": {
        "precision": 0.3811074918566775,
        "recall": 0.7112462006079028,
        "f1-score": 0.4962884411452811,
        "accuracy": 0.7112462006079028,
        "support": 329,
        "tp": 234,
        "fp": 380,
        "fn": 95,
        "tn": 3112
    }
}