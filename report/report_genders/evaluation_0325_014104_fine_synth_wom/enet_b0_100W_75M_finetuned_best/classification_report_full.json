{
    "overall": {
        "accuracy": 0.8766066838046273,
        "macro avg": {
            "precision": 0.8742264457981855,
            "recall": 0.8766875084553356,
            "f1-score": 0.8744608486314627,
            "support": 778
        },
        "weighted avg": {
            "precision": 0.8772612459342103,
            "recall": 0.8766066838046273,
            "f1-score": 0.8759379303723132,
            "support": 778
        }
    },
    "per_class": {},
    "Angry": {
        "precision": 0.7978723404255319,
        "recall": 0.7978723404255319,
        "f1-score": 0.7978723404255319,
        "accuracy": 0.7978723404255319,
        "support": 94,
        "tp": 75,
        "fp": 19,
        "fn": 19,
        "tn": 665
    },
    "Contempt": {
        "precision": 0.8333333333333334,
        "recall": 0.7471264367816092,
        "f1-score": 0.787878787878788,
        "accuracy": 0.7471264367816092,
        "support": 87,
        "tp": 65,
        "fp": 13,
        "fn": 22,
        "tn": 678
    },
    "Disgust": {
        "precision": 0.7864077669902912,
        "recall": 0.8617021276595744,
        "f1-score": 0.8223350253807107,
        "accuracy": 0.8617021276595744,
        "support": 94,
        "tp": 81,
        "fp": 22,
        "fn": 13,
        "tn": 662
    },
    "Fear": {
        "precision": 0.9259259259259259,
        "recall": 0.847457627118644,
        "f1-score": 0.8849557522123893,
        "accuracy": 0.847457627118644,
        "support": 118,
        "tp": 100,
        "fp": 8,
        "fn": 18,
        "tn": 652
    },
    "Happiness": {
        "precision": 0.9428571428571428,
        "recall": 1.0,
        "f1-score": 0.9705882352941176,
        "accuracy": 1.0,
        "support": 99,
        "tp": 99,
        "fp": 6,
        "fn": 0,
        "tn": 673
    },
    "Neutral": {
        "precision": 0.9101123595505618,
        "recall": 0.9642857142857143,
        "f1-score": 0.9364161849710984,
        "accuracy": 0.9642857142857143,
        "support": 84,
        "tp": 81,
        "fp": 8,
        "fn": 3,
        "tn": 686
    },
    "Sadness": {
        "precision": 0.9181818181818182,
        "recall": 0.8859649122807017,
        "f1-score": 0.9017857142857142,
        "accuracy": 0.8859649122807017,
        "support": 114,
        "tp": 101,
        "fp": 9,
        "fn": 13,
        "tn": 655
    },
    "Surprise": {
        "precision": 0.8791208791208791,
        "recall": 0.9090909090909091,
        "f1-score": 0.8938547486033518,
        "accuracy": 0.9090909090909091,
        "support": 88,
        "tp": 80,
        "fp": 11,
        "fn": 8,
        "tn": 679
    }
}