{
    "overall": {
        "accuracy": 0.6835906830672599,
        "macro avg": {
            "precision": 0.6745027766408616,
            "recall": 0.6382602349764601,
            "f1-score": 0.65355772718122,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.7161248462714551,
            "recall": 0.6835906830672599,
            "f1-score": 0.6971312069614298,
            "support": 3821
        }
    },
    "Angry": {
        "precision": 0.6772486772486772,
        "recall": 0.5898617511520737,
        "f1-score": 0.6305418719211822,
        "accuracy": 0.5898617511520737,
        "support": 434,
        "True Positives": 256,
        "False Positives": 122,
        "False Negatives": 178,
        "True Negatives": 3265
    },
    "Disgust": {
        "precision": 0.4781704781704782,
        "recall": 0.5637254901960784,
        "f1-score": 0.5174353205849269,
        "accuracy": 0.5637254901960784,
        "support": 408,
        "True Positives": 230,
        "False Positives": 251,
        "False Negatives": 178,
        "True Negatives": 3162
    },
    "Fear": {
        "precision": 0.5977011494252874,
        "recall": 0.50814332247557,
        "f1-score": 0.5492957746478874,
        "accuracy": 0.50814332247557,
        "support": 307,
        "True Positives": 156,
        "False Positives": 105,
        "False Negatives": 151,
        "True Negatives": 3409
    },
    "Happiness": {
        "precision": 0.8237232289950577,
        "recall": 0.8438818565400844,
        "f1-score": 0.8336807002917883,
        "accuracy": 0.8438818565400844,
        "support": 1185,
        "True Positives": 1000,
        "False Positives": 214,
        "False Negatives": 185,
        "True Negatives": 2422
    },
    "Neutral": {
        "precision": 0.7829313543599258,
        "recall": 0.6205882352941177,
        "f1-score": 0.6923707957342083,
        "accuracy": 0.6205882352941177,
        "support": 680,
        "True Positives": 422,
        "False Positives": 117,
        "False Negatives": 258,
        "True Negatives": 3024
    },
    "Sadness": {
        "precision": 0.72,
        "recall": 0.7154811715481172,
        "f1-score": 0.7177334732423923,
        "accuracy": 0.7154811715481172,
        "support": 478,
        "True Positives": 342,
        "False Positives": 133,
        "False Negatives": 136,
        "True Negatives": 3210
    },
    "Surprise": {
        "precision": 0.6417445482866043,
        "recall": 0.6261398176291794,
        "f1-score": 0.6338461538461538,
        "accuracy": 0.6261398176291794,
        "support": 329,
        "True Positives": 206,
        "False Positives": 115,
        "False Negatives": 123,
        "True Negatives": 3377
    }
}