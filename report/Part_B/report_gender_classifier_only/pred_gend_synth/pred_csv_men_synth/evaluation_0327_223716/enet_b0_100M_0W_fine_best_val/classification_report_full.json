{
    "overall": {
        "accuracy": 0.6169665809768637,
        "macro avg": {
            "precision": 0.6658273651944766,
            "recall": 0.6123578332184394,
            "f1-score": 0.5915175932083983,
            "support": 778
        },
        "weighted avg": {
            "precision": 0.6823554132289333,
            "recall": 0.6169665809768637,
            "f1-score": 0.6053482537602871,
            "support": 778
        }
    },
    "Angry": {
        "precision": 0.49586776859504134,
        "recall": 0.6382978723404256,
        "f1-score": 0.558139534883721,
        "accuracy": 0.6382978723404256,
        "support": 94,
        "True Positives": 60,
        "False Positives": 61,
        "False Negatives": 34,
        "True Negatives": 623
    },
    "Contempt": {
        "precision": 0.4375,
        "recall": 0.08045977011494253,
        "f1-score": 0.13592233009708737,
        "accuracy": 0.08045977011494253,
        "support": 87,
        "True Positives": 7,
        "False Positives": 9,
        "False Negatives": 80,
        "True Negatives": 682
    },
    "Disgust": {
        "precision": 0.7714285714285715,
        "recall": 0.2872340425531915,
        "f1-score": 0.4186046511627907,
        "accuracy": 0.2872340425531915,
        "support": 94,
        "True Positives": 27,
        "False Positives": 8,
        "False Negatives": 67,
        "True Negatives": 676
    },
    "Fear": {
        "precision": 0.8045977011494253,
        "recall": 0.5932203389830508,
        "f1-score": 0.6829268292682927,
        "accuracy": 0.5932203389830508,
        "support": 118,
        "True Positives": 70,
        "False Positives": 17,
        "False Negatives": 48,
        "True Negatives": 643
    },
    "Happiness": {
        "precision": 0.8596491228070176,
        "recall": 0.98989898989899,
        "f1-score": 0.9201877934272301,
        "accuracy": 0.98989898989899,
        "support": 99,
        "True Positives": 98,
        "False Positives": 16,
        "False Negatives": 1,
        "True Negatives": 663
    },
    "Neutral": {
        "precision": 0.2909090909090909,
        "recall": 0.7619047619047619,
        "f1-score": 0.4210526315789473,
        "accuracy": 0.7619047619047619,
        "support": 84,
        "True Positives": 64,
        "False Positives": 156,
        "False Negatives": 20,
        "True Negatives": 538
    },
    "Sadness": {
        "precision": 0.8666666666666667,
        "recall": 0.6842105263157895,
        "f1-score": 0.7647058823529413,
        "accuracy": 0.6842105263157895,
        "support": 114,
        "True Positives": 78,
        "False Positives": 12,
        "False Negatives": 36,
        "True Negatives": 652
    },
    "Surprise": {
        "precision": 0.8,
        "recall": 0.8636363636363636,
        "f1-score": 0.8306010928961749,
        "accuracy": 0.8636363636363636,
        "support": 88,
        "True Positives": 76,
        "False Positives": 19,
        "False Negatives": 12,
        "True Negatives": 671
    }
}