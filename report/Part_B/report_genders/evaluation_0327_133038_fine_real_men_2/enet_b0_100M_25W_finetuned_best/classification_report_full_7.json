{
    "overall": {
        "accuracy": 0.557183983250458,
        "macro avg": {
            "precision": 0.5803303054620488,
            "recall": 0.5444961162412854,
            "f1-score": 0.5346473312174127,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.6543911960186198,
            "recall": 0.557183983250458,
            "f1-score": 0.5790201706067185,
            "support": 3821
        }
    },
    "Angry": {
        "precision": 0.569620253164557,
        "recall": 0.2073732718894009,
        "f1-score": 0.30405405405405406,
        "accuracy": 0.2073732718894009,
        "support": 434,
        "True Positives": 90,
        "False Positives": 68,
        "False Negatives": 344,
        "True Negatives": 3319
    },
    "Disgust": {
        "precision": 0.3157894736842105,
        "recall": 0.6617647058823529,
        "f1-score": 0.42755344418052255,
        "accuracy": 0.6617647058823529,
        "support": 408,
        "True Positives": 270,
        "False Positives": 585,
        "False Negatives": 138,
        "True Negatives": 2828
    },
    "Fear": {
        "precision": 0.549645390070922,
        "recall": 0.504885993485342,
        "f1-score": 0.5263157894736842,
        "accuracy": 0.504885993485342,
        "support": 307,
        "True Positives": 155,
        "False Positives": 127,
        "False Negatives": 152,
        "True Negatives": 3387
    },
    "Happiness": {
        "precision": 0.9211165048543689,
        "recall": 0.640506329113924,
        "f1-score": 0.7555998008959681,
        "accuracy": 0.640506329113924,
        "support": 1185,
        "True Positives": 759,
        "False Positives": 65,
        "False Negatives": 426,
        "True Negatives": 2571
    },
    "Neutral": {
        "precision": 0.5928030303030303,
        "recall": 0.4602941176470588,
        "f1-score": 0.5182119205298014,
        "accuracy": 0.4602941176470588,
        "support": 680,
        "True Positives": 313,
        "False Positives": 215,
        "False Negatives": 367,
        "True Negatives": 2926
    },
    "Sadness": {
        "precision": 0.6356589147286822,
        "recall": 0.6861924686192469,
        "f1-score": 0.6599597585513078,
        "accuracy": 0.6861924686192469,
        "support": 478,
        "True Positives": 328,
        "False Positives": 188,
        "False Negatives": 150,
        "True Negatives": 3155
    },
    "Surprise": {
        "precision": 0.47767857142857145,
        "recall": 0.6504559270516718,
        "f1-score": 0.5508365508365508,
        "accuracy": 0.6504559270516718,
        "support": 329,
        "True Positives": 214,
        "False Positives": 234,
        "False Negatives": 115,
        "True Negatives": 3258
    }
}