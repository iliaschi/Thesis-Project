{
    "overall": {
        "accuracy": 0.5841402774142894,
        "macro avg": {
            "precision": 0.5297444454013904,
            "recall": 0.4872137418805619,
            "f1-score": 0.48176465715497496,
            "support": 3821
        },
        "weighted avg": {
            "precision": 0.6710757321891535,
            "recall": 0.5841402774142894,
            "f1-score": 0.6022361937914825,
            "support": 3821
        }
    },
    "per_class": {},
    "Angry": {
        "precision": 0.6442953020134228,
        "recall": 0.22119815668202766,
        "f1-score": 0.3293310463121784,
        "accuracy": 0.22119815668202766,
        "support": 434,
        "tp": 96,
        "fp": 53,
        "fn": 338,
        "tn": 3334
    },
    "Contempt": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "accuracy": 0.0,
        "support": 0,
        "tp": 0,
        "fp": 172,
        "fn": 0,
        "tn": 3649
    },
    "Disgust": {
        "precision": 0.3222354340071344,
        "recall": 0.6642156862745098,
        "f1-score": 0.433947157726181,
        "accuracy": 0.6642156862745098,
        "support": 408,
        "tp": 271,
        "fp": 570,
        "fn": 137,
        "tn": 2843
    },
    "Fear": {
        "precision": 0.5670995670995671,
        "recall": 0.42671009771986973,
        "f1-score": 0.48698884758364314,
        "accuracy": 0.42671009771986973,
        "support": 307,
        "tp": 131,
        "fp": 100,
        "fn": 176,
        "tn": 3414
    },
    "Happiness": {
        "precision": 0.8802966101694916,
        "recall": 0.7012658227848101,
        "f1-score": 0.7806481916392672,
        "accuracy": 0.7012658227848101,
        "support": 1185,
        "tp": 831,
        "fp": 113,
        "fn": 354,
        "tn": 2523
    },
    "Neutral": {
        "precision": 0.6703296703296703,
        "recall": 0.538235294117647,
        "f1-score": 0.5970636215334421,
        "accuracy": 0.538235294117647,
        "support": 680,
        "tp": 366,
        "fp": 180,
        "fn": 314,
        "tn": 2961
    },
    "Sadness": {
        "precision": 0.6741071428571429,
        "recall": 0.6317991631799164,
        "f1-score": 0.6522678185745141,
        "accuracy": 0.6317991631799164,
        "support": 478,
        "tp": 302,
        "fp": 146,
        "fn": 176,
        "tn": 3197
    },
    "Surprise": {
        "precision": 0.47959183673469385,
        "recall": 0.7142857142857143,
        "f1-score": 0.5738705738705739,
        "accuracy": 0.7142857142857143,
        "support": 329,
        "tp": 235,
        "fp": 255,
        "fn": 94,
        "tn": 3237
    }
}