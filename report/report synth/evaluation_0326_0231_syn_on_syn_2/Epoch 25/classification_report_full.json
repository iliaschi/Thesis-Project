{
    "overall": {
        "accuracy": 0.961439588688946,
        "macro avg": {
            "precision": 0.9612599644666988,
            "recall": 0.9613619506885664,
            "f1-score": 0.960956578073842,
            "support": 778
        },
        "weighted avg": {
            "precision": 0.9621766901853657,
            "recall": 0.961439588688946,
            "f1-score": 0.961473326407989,
            "support": 778
        }
    },
    "Angry": {
        "precision": 0.9,
        "recall": 0.9574468085106383,
        "f1-score": 0.9278350515463918,
        "accuracy": 0.9574468085106383,
        "support": 94,
        "True Positives": 90,
        "False Positives": 10,
        "False Negatives": 4,
        "True Negatives": 674
    },
    "Contempt": {
        "precision": 0.9753086419753086,
        "recall": 0.9080459770114943,
        "f1-score": 0.9404761904761905,
        "accuracy": 0.9080459770114943,
        "support": 87,
        "True Positives": 79,
        "False Positives": 2,
        "False Negatives": 8,
        "True Negatives": 689
    },
    "Disgust": {
        "precision": 0.9468085106382979,
        "recall": 0.9468085106382979,
        "f1-score": 0.9468085106382979,
        "accuracy": 0.9468085106382979,
        "support": 94,
        "True Positives": 89,
        "False Positives": 5,
        "False Negatives": 5,
        "True Negatives": 679
    },
    "Fear": {
        "precision": 0.9741379310344828,
        "recall": 0.9576271186440678,
        "f1-score": 0.9658119658119658,
        "accuracy": 0.9576271186440678,
        "support": 118,
        "True Positives": 113,
        "False Positives": 3,
        "False Negatives": 5,
        "True Negatives": 657
    },
    "Happiness": {
        "precision": 0.99,
        "recall": 1.0,
        "f1-score": 0.9949748743718593,
        "accuracy": 1.0,
        "support": 99,
        "True Positives": 99,
        "False Positives": 1,
        "False Negatives": 0,
        "True Negatives": 678
    },
    "Neutral": {
        "precision": 0.9761904761904762,
        "recall": 0.9761904761904762,
        "f1-score": 0.9761904761904762,
        "accuracy": 0.9761904761904762,
        "support": 84,
        "True Positives": 82,
        "False Positives": 2,
        "False Negatives": 2,
        "True Negatives": 692
    },
    "Sadness": {
        "precision": 0.9819819819819819,
        "recall": 0.956140350877193,
        "f1-score": 0.9688888888888889,
        "accuracy": 0.956140350877193,
        "support": 114,
        "True Positives": 109,
        "False Positives": 2,
        "False Negatives": 5,
        "True Negatives": 662
    },
    "Surprise": {
        "precision": 0.9456521739130435,
        "recall": 0.9886363636363636,
        "f1-score": 0.9666666666666666,
        "accuracy": 0.9886363636363636,
        "support": 88,
        "True Positives": 87,
        "False Positives": 5,
        "False Negatives": 1,
        "True Negatives": 685
    }
}